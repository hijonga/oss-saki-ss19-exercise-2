{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume NER\n",
    "## Extract Information from Resumes using NER (Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Data Exploration and preprocessing\n",
    "In this first part of the challenge, we will load and examine the dataset we will be working with. We will also prepare the data for training which we will start in the second part of the challenge. You will be required to program some basic python pertaining to file loading, data conversion, and basic dictionaries and array manipulation. If you are experienced with Python, this will be easy. If you are new to python and/or programming, it will be a good opportunity to learn some basic programming you will need for data loading and exploration.\n",
    "\n",
    "* *If you need help setting up python or running this notebook, please get help from the  assistants to the professor*\n",
    "* *It might be helpful to try your code out first in a python ide like pycharm before copying it an running it here in this notebook*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Dataset\n",
    "The dataset we will be using is located in the dataset folder included in the project. Verify the data is available by executing the code cell below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataset_path = \"../dataset/Entity Recognition in Resumes.json\"\n",
    "print(\"Path exists? {}\".format(os.path.exists(dataset_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good? OK then let's load the dataset. The dataset is structured so that each line of text is a resume. \n",
    "You will do the following:\n",
    "1. using python's built-in \"open\" function, get a filehandle to the dataset (tip don't forget the file is utf8!)\n",
    "2. load the data into an array of resumes (each text line is one resume) \n",
    "3. use the print function to print how many resumes were loaded\n",
    "4. use the print function to output one of the resumes so we can see how the resumes look in raw text form \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701\n",
      "Sample resume:{\"content\": \"Afreen Jamadar\\nActive member of IIIT Committee in Third year\\n\\nSangli, Maharashtra - Email me on Indeed: indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\\n\\nI wish to use my knowledge, skills and conceptual understanding to create excellent team\\nenvironments and work consistently achieving organization objectives believes in taking initiative\\nand work to excellence in my work.\\n\\nWORK EXPERIENCE\\n\\nActive member of IIIT Committee in Third year\\n\\nCisco Networking -  Kanpur, Uttar Pradesh\\n\\norganized by Techkriti IIT Kanpur and Azure Skynet.\\nPERSONALLITY TRAITS:\\n• Quick learning ability\\n• hard working\\n\\nEDUCATION\\n\\nPG-DAC\\n\\nCDAC ACTS\\n\\n2017\\n\\nBachelor of Engg in Information Technology\\n\\nShivaji University Kolhapur -  Kolhapur, Maharashtra\\n\\n2016\\n\\nSKILLS\\n\\nDatabase (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\\n\\nhttps://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\",\"annotation\":[{\"label\":[\"Email Address\"],\"points\":[{\"start\":1155,\"end\":1198,\"text\":\"indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\"}]},{\"label\":[\"Links\"],\"points\":[{\"start\":1143,\"end\":1239,\"text\":\"https://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\"}]},{\"label\":[\"Skills\"],\"points\":[{\"start\":743,\"end\":1140,\"text\":\"Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\"}]},{\"label\":[\"Graduation Year\"],\"points\":[{\"start\":729,\"end\":732,\"text\":\"2016\"}]},{\"label\":[\"College Name\"],\"points\":[{\"start\":675,\"end\":702,\"text\":\"Shivaji University Kolhapur \"}]},{\"label\":[\"Degree\"],\"points\":[{\"start\":631,\"end\":672,\"text\":\"Bachelor of Engg in Information Technology\"}]},{\"label\":[\"Graduation Year\"],\"points\":[{\"start\":625,\"end\":629,\"text\":\"2017\\n\"}]},{\"label\":[\"College Name\"],\"points\":[{\"start\":614,\"end\":622,\"text\":\"CDAC ACTS\"}]},{\"label\":[\"Degree\"],\"points\":[{\"start\":606,\"end\":611,\"text\":\"PG-DAC\"}]},{\"label\":[\"Companies worked at\"],\"points\":[{\"start\":438,\"end\":453,\"text\":\"Cisco Networking\"}]},{\"label\":[\"Email Address\"],\"points\":[{\"start\":104,\"end\":147,\"text\":\"indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\"}]},{\"label\":[\"Location\"],\"points\":[{\"start\":62,\"end\":67,\"text\":\"Sangli\"}]},{\"label\":[\"Name\"],\"points\":[{\"start\":0,\"end\":13,\"text\":\"Afreen Jamadar\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1527844872000,\"last_updated_at\":1537724086000,\"sec_taken\":0,\"last_updated_by\":\"BIQNZm4INNfvByMqkaVwVt6OZTv2\",\"status\":\"done\",\"evaluation\":\"CORRECT\"}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## use the \"open\" function to get a filehandle. \n",
    "with open(dataset_path,encoding=\"utf8\") as f:\n",
    "    ## use the filehandle to read all lines into an array of text lines. \n",
    "    all_data= f.readlines()\n",
    "    ## print how many lines were loaded\n",
    "    print(len(all_data))\n",
    "    ## now print one resume/line to see how the resumes look in raw text form\n",
    "    print(\"Sample resume:\"+all_data[0])\n",
    "    #TODO print sample resume\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the dataset to json\n",
    "As we can see, the resumes are not in a convenient human-readable form, but are json dictionaries. We want to work with the resumes as python dictionaries and not as raw text, so we will convert the resumes from text to dictionaries. We will do the following:\n",
    "1. Import the json module\n",
    "2. Loop through all of the text lines and use the json 'loads' function to convert the line to a python dictionary. Tip - you can use a 'for' loop, or if you want to get fancy, a python 'list comprehension' to accomplish this. \n",
    "3. Select one of the converted resumes so that we can examine its structure.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import json module to load json strings\n",
    "import json\n",
    "## using a for loop or a list comprehension, cycle through all lines (loaded above) and convert them to dictionaries \n",
    "## using json loads function. Make sure all converted resumes are stored in the 'all_resumes' array below  \n",
    "all_resumes = []\n",
    "for line in all_data:\n",
    "    all_resumes.append(json.loads(line))\n",
    "    \n",
    "\n",
    "## select one resume to examine from the all_resumes list\n",
    "resume = all_resumes[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore the resume data structure\n",
    "You should have one sample resume saved in the \"resume\" variable. Now we will examine the resume dictionary. Complete the code below to see the keys in the dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys and values in resume:\n",
      "content-----------------------------Alok Khandai\n",
      "Operational Analyst (SQL DBA) Engineer - UNISYS\n",
      "\n",
      "Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Alok-Khandai/5be849e443b8f467\n",
      "\n",
      "❖ Having 3.5 Years of IT experience in SQL Database Administration, System Analysis, Design,\n",
      "Development & Support of MS SQL Servers in Production, Development environments &\n",
      "Replication and Cluster Server Environments.\n",
      "❖ Working Experience with relational database such as SQL.\n",
      "❖ Experience in Installation, Configuration, Maintenance and Administration of SQL Server.\n",
      "❖ Experience in upgrading SQL Server.\n",
      "❖ Good experience with implementing DR solution, High Availability of database servers using\n",
      "Database mirroring and replications and Log Shipping.\n",
      "❖ Experience in implementing SQL Server security and Object permissions like maintaining\n",
      "Database authentication modes, creation of users, configuring permissions and assigning roles\n",
      "to users.\n",
      "❖ Experience in creating Jobs, Alerts, SQL Mail Agent\n",
      "❖ Experience in performing integrity checks. Methods include configuring the database\n",
      "maintenance plan wizard and DBCC utilities\n",
      "❖ Experience in using Performance Monitor, SQL Profiler and optimizing the queries, tracing long\n",
      "running queries and deadlocks.\n",
      "❖ Experience in applying patches and service packs to keep the database at current patch level.\n",
      "❖ Ability to manage own work and multitask to meet tight deadlines without losing sight of\n",
      "priorities..\n",
      "\n",
      "Willing to relocate to: Bengaluru, Karnataka\n",
      "\n",
      "WORK EXPERIENCE\n",
      "\n",
      "Operational Analyst (SQL DBA) Engineer\n",
      "\n",
      "UNISYS -  Bengaluru, Karnataka -\n",
      "\n",
      "July 2016 to Present\n",
      "\n",
      "❖ Having 3.5 Years of IT experience in SQL Database Administration, System Analysis, Design,\n",
      "Development & Support of MS SQL Servers in Production, Development environments &\n",
      "Replication and Cluster Server Environments.\n",
      "❖ Working Experience with relational database such as SQL.\n",
      "❖ Experience in Installation, Configuration, Maintenance and Administration of SQL Server. \n",
      "❖ Experience in upgrading SQL Server.\n",
      "❖ Good experience with implementing DR solution, High Availability of database servers using\n",
      "Database mirroring and replications and Log Shipping.\n",
      "❖ Experience in implementing SQL Server security and Object permissions like maintaining\n",
      "Database authentication modes, creation of users, configuring permissions and assigning roles\n",
      "to users.\n",
      "\n",
      "DBA Support Analyst\n",
      "\n",
      "Microsoft Corporation -  Redmond, WA -\n",
      "\n",
      "https://www.indeed.com/r/Alok-Khandai/5be849e443b8f467?isid=rex-download&ikw=download-top&co=IN\n",
      "\n",
      "\n",
      "July 2016 to Present\n",
      "\n",
      "Client Description:\n",
      "Microsoft Corporation is an American public multinational corporation headquartered in\n",
      "Redmond, Washington, USA that develops, manufactures, licenses, and supports a wide range of\n",
      "products and services predominantly related to computing through its various product divisions.\n",
      "\n",
      "Environment:\n",
      "Microsoft has E2E development and production environment of more than 25000 servers and\n",
      "applications. We are responsible for pro-active monitoring of all the servers and their jobs using\n",
      "monitoring tools to reduce critical business impact by alerting respective peer teams. Microsoft\n",
      "Service Enterprise an ITSM tools are used for ticketing and SharePoint portal is used to store all\n",
      "technical and process documentation.\n",
      "\n",
      "Roles and Responsibilities:\n",
      "• Responsible for Database support, troubleshooting, planning and migration. Resource planning\n",
      "and coordination for application migrations with project managers, application and web app\n",
      "teams. Project involved guidance and adherence to standardized procedures for planned data\n",
      "center consolidation for worldwide centers using in-house corporate and third party applications\n",
      "based on SQL 2000 in upgrade project to SQL 2005.\n",
      "• Monitoring of database size and disk space in Production, Staging & Development environments\n",
      "• Performed installation of SQL Enterprise 2005 64bit version on Windows 2003 servers on\n",
      "Enterprise systems of clustered and standalone servers in enterprise Data Centers. Patch\n",
      "applications.\n",
      "• Failover cluster testing and resolution on HP servers as well as monitoring and backup reporting\n",
      "setup with Microsoft Operations Manager and backup teams.\n",
      "• Working in Microsoft production environment which includes applications and servers.\n",
      "• Configured Transactional Replication and Log Shipping with SQL Server Management Studio as\n",
      "well as basic account management and troubleshooting with connectivity, security and firewall\n",
      "issues.\n",
      "• Handling issues related to Server Availability, Performance.\n",
      "• Performed Production support and on Call duties\n",
      "• Conducted Performance Tuning using SQL Profiler and Windows Performance Monitor.\n",
      "• Worked with various business groups while developing their applications, assisting in database\n",
      "design, installing SQL Server clients, phasing from development to QA and to Production\n",
      "environment.\n",
      "\n",
      "Previous Project\n",
      "❖ Project Title: Finance Support\n",
      "❖ Client: Costco Wholesale Corporation (USA)\n",
      "❖ Team size: 22\n",
      "❖ Role: DBA Support Analyst\n",
      "❖ Environment: Window 10\n",
      "\n",
      "(SQL DBA Analyst) Engineer\n",
      "\n",
      "HCL Technologies -  Bengaluru, Karnataka -\n",
      "\n",
      "November 2014 to July 2016\n",
      "\n",
      "〓 Performed server installation and configurations for SQL Server 2005 and SQL Server 2000.\n",
      "\n",
      "\n",
      "\n",
      "〓 Performed installation of SQL Server Service Packs\n",
      "〓 Upgraded databases from SQL Server 2000 to SQL Server 2005.\n",
      "〓 Scheduled Full and Transactional log backups for the user created and system databases in\n",
      "the production environment using the Database Maintenance Plan Wizard.\n",
      "〓 Setup backup and restoration jobs for development and QA environments\n",
      "〓 Created transactional replication for the reporting applications.\n",
      "〓 Implemented disaster recovery solution at the remote site for the production databases using\n",
      "Log Shipping.\n",
      "〓 Used System monitor to find the bottlenecks in CPU, Disk I/O and memory devices and\n",
      "improved the database server performance.\n",
      "〓 Used SQL Server Profiler to monitor and record database activities of particular users and\n",
      "applications.\n",
      "〓 Used DBCC commands to troubleshoot issues related to database consistency\n",
      "〓 Worked with various business groups while developing their applications, assisting in database\n",
      "design, installing SQL Server clients, phasing from development to QA and to Production\n",
      "environment\n",
      "\n",
      "Microsoft Corporation -\n",
      "\n",
      "November 2014 to July 2016\n",
      "\n",
      "Client Description:\n",
      "\n",
      "❖ Costco Wholesale Corporation operates an international chain of membership warehouses,\n",
      "mainly under the \"Costco Wholesale\" name, that carry quality, brand name merchandise at\n",
      "substantially lower prices than are typically found at conventional wholesale or retail sources. The\n",
      "warehouses are designed to help small-to-medium-sized businesses reduce costs in purchasing\n",
      "for resale and for everyday business use. Individuals may also purchase for their personal needs.\n",
      "\n",
      "❖ Responsibilities:\n",
      "\n",
      "➢ Performed server installation and configurations for SQL Server 2005 and SQL Server 2000.\n",
      "➢ Performed installation of SQL Server Service Packs\n",
      "➢ Upgraded databases from SQL Server 2000 to SQL Server 2005.\n",
      "➢ Scheduled Full and Transactional log backups for the user created and system databases in\n",
      "the production environment using the Database Maintenance Plan Wizard.\n",
      "➢ Setup backup and restoration jobs for development and QA environments\n",
      "➢ Created transactional replication for the reporting applications.\n",
      "➢ Implemented disaster recovery solution at the remote site for the production databases using\n",
      "Log Shipping.\n",
      "➢ Used System monitor to find the bottlenecks in CPU, Disk I/O and memory devices and improved\n",
      "the database server performance.\n",
      "➢ Used SQL Server Profiler to monitor and record database activities of particular users and\n",
      "applications.\n",
      "➢ Used DBCC commands to troubleshoot issues related to database consistency\n",
      "➢ Worked with various business groups while developing their applications, assisting in database\n",
      "design, installing SQL Server clients, phasing from development to QA and to Production\n",
      "environment\n",
      "\n",
      "\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "B.Tech in Computer Science and Engineering in CSE\n",
      "\n",
      "Indira Gandhi Institute Of Technology\n",
      "\n",
      "2012\n",
      "\n",
      "SKILLS\n",
      "\n",
      "Database (3 years), SQL (3 years), Sql Dba\n",
      "\n",
      "ADDITIONAL INFORMATION\n",
      "\n",
      "TECHNICAL PROFICIENCY\n",
      "❖ Operating Environment: […] Windows95/98/XP/NT\n",
      "❖ Database Tool: SQL Management Studio (MSSQL), Business\n",
      "Development Studio, Visual studio 2005\n",
      "❖ Database Language: SQL, PL/SQL\n",
      "❖ Ticket Tracking Tool: Service Now\n",
      "❖ Reporting Tools: MS Reporting Services, SAS\n",
      "❖ Languages: C, C++, PL/SQL\n",
      "annotation-----------------------------[{'label': ['Skills'], 'points': [{'start': 8098, 'end': 8383, 'text': '❖ Operating Environment: […] Windows95/98/XP/NT\\n❖ Database Tool: SQL Management Studio (MSSQL), Business\\nDevelopment Studio, Visual studio 2005\\n❖ Database Language: SQL, PL/SQL\\n❖ Ticket Tracking Tool: Service Now\\n❖ Reporting Tools: MS Reporting Services, SAS\\n❖ Languages: C, C++, PL/SQL'}]}, {'label': ['Skills'], 'points': [{'start': 8008, 'end': 8049, 'text': 'Database (3 years), SQL (3 years), Sql Dba'}]}, {'label': ['Graduation Year'], 'points': [{'start': 7994, 'end': 7997, 'text': '2012'}]}, {'label': ['College Name'], 'points': [{'start': 7955, 'end': 7991, 'text': 'Indira Gandhi Institute Of Technology'}]}, {'label': ['College Name'], 'points': [{'start': 7904, 'end': 7952, 'text': 'B.Tech in Computer Science and Engineering in CSE'}]}, {'label': ['Companies worked at'], 'points': [{'start': 6199, 'end': 6219, 'text': 'Microsoft Corporation'}]}, {'label': ['Location'], 'points': [{'start': 5016, 'end': 5024, 'text': 'Bengaluru'}]}, {'label': ['Companies worked at'], 'points': [{'start': 4996, 'end': 5011, 'text': 'HCL Technologies'}]}, {'label': ['Designation'], 'points': [{'start': 4969, 'end': 4983, 'text': 'SQL DBA Analyst'}]}, {'label': ['Designation'], 'points': [{'start': 4922, 'end': 4940, 'text': 'DBA Support Analyst'}]}, {'label': ['projects'], 'points': [{'start': 4836, 'end': 4851, 'text': ' Finance Support'}]}, {'label': ['Companies worked at'], 'points': [{'start': 2519, 'end': 2539, 'text': 'Microsoft Corporation'}]}, {'label': ['Email Address'], 'points': [{'start': 2391, 'end': 2432, 'text': 'indeed.com/r/Alok-Khandai/5be849e443b8f467'}]}, {'label': ['Companies worked at'], 'points': [{'start': 2339, 'end': 2359, 'text': 'Microsoft Corporation'}]}, {'label': ['Designation'], 'points': [{'start': 2318, 'end': 2336, 'text': 'DBA Support Analyst'}]}, {'label': ['Skills'], 'points': [{'start': 1607, 'end': 1658, 'text': 'SQL Database Administration, System Analysis, Design'}]}, {'label': ['Years of Experience'], 'points': [{'start': 1577, 'end': 1585, 'text': '3.5 Years'}]}, {'label': ['Location'], 'points': [{'start': 1522, 'end': 1530, 'text': 'Bengaluru'}]}, {'label': ['Companies worked at'], 'points': [{'start': 1512, 'end': 1517, 'text': 'UNISYS'}]}, {'label': ['Designation'], 'points': [{'start': 1472, 'end': 1509, 'text': 'Operational Analyst (SQL DBA) Engineer'}]}, {'label': ['Location'], 'points': [{'start': 1433, 'end': 1441, 'text': 'Bengaluru'}]}, {'label': ['Skills'], 'points': [{'start': 188, 'end': 239, 'text': 'SQL Database Administration, System Analysis, Design'}]}, {'label': ['Email Address'], 'points': [{'start': 105, 'end': 146, 'text': 'indeed.com/r/Alok-Khandai/5be849e443b8f467'}]}, {'label': ['Location'], 'points': [{'start': 62, 'end': 70, 'text': 'Bengaluru'}]}, {'label': ['Companies worked at'], 'points': [{'start': 54, 'end': 59, 'text': 'UNISYS'}]}, {'label': ['Designation'], 'points': [{'start': 13, 'end': 50, 'text': 'Operational Analyst (SQL DBA) Engineer'}]}, {'label': ['Name'], 'points': [{'start': 0, 'end': 11, 'text': 'Alok Khandai'}]}]\n",
      "extras-----------------------------None\n",
      "metadata-----------------------------{'first_done_at': 1527845028000, 'last_updated_at': 1538662820000, 'sec_taken': 0, 'last_updated_by': 'BIQNZm4INNfvByMqkaVwVt6OZTv2', 'status': 'done', 'evaluation': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "## explore keys in cv\n",
    "print(\"keys and values in resume:\")\n",
    "## TODO print out the keys and values for the sample resume\n",
    "\n",
    "for key,val in resume.items():\n",
    "    print (str(key)+\"-----------------------------\"+str(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question: which key do you think points to the text content of the resume?\n",
    "content\n",
    "##### Question: which key do you think points to the list of entity annotations? \n",
    "annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your answers above, see if you were right by printing the text content and the entity list by completing and executing the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alok Khandai\n",
      "Operational Analyst (SQL DBA) Engineer - UNISYS\n",
      "\n",
      "Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Alok-Khandai/5be849e443b8f467\n",
      "\n",
      "❖ Having 3.5 Years of IT experience in SQL Database Administration, System Analysis, Design,\n",
      "Development & Support of MS SQL Servers in Production, Development environments &\n",
      "Replication and Cluster Server Environments.\n",
      "❖ Working Experience with relational database such as SQL.\n",
      "❖ Experience in Installation, Configuration, Maintenance and Administration of SQL Server.\n",
      "❖ Experience in upgrading SQL Server.\n",
      "❖ Good experience with implementing DR solution, High Availability of database servers using\n",
      "Database mirroring and replications and Log Shipping.\n",
      "❖ Experience in implementing SQL Server security and Object permissions like maintaining\n",
      "Database authentication modes, creation of users, configuring permissions and assigning roles\n",
      "to users.\n",
      "❖ Experience in creating Jobs, Alerts, SQL Mail Agent\n",
      "❖ Experience in performing integrity checks. Methods include configuring the database\n",
      "maintenance plan wizard and DBCC utilities\n",
      "❖ Experience in using Performance Monitor, SQL Profiler and optimizing the queries, tracing long\n",
      "running queries and deadlocks.\n",
      "❖ Experience in applying patches and service packs to keep the database at current patch level.\n",
      "❖ Ability to manage own work and multitask to meet tight deadlines without losing sight of\n",
      "priorities..\n",
      "\n",
      "Willing to relocate to: Bengaluru, Karnataka\n",
      "\n",
      "WORK EXPERIENCE\n",
      "\n",
      "Operational Analyst (SQL DBA) Engineer\n",
      "\n",
      "UNISYS -  Bengaluru, Karnataka -\n",
      "\n",
      "July 2016 to Present\n",
      "\n",
      "❖ Having 3.5 Years of IT experience in SQL Database Administration, System Analysis, Design,\n",
      "Development & Support of MS SQL Servers in Production, Development environments &\n",
      "Replication and Cluster Server Environments.\n",
      "❖ Working Experience with relational database such as SQL.\n",
      "❖ Experience in Installation, Configuration, Maintenance and Administration of SQL Server. \n",
      "❖ Experience in upgrading SQL Server.\n",
      "❖ Good experience with implementing DR solution, High Availability of database servers using\n",
      "Database mirroring and replications and Log Shipping.\n",
      "❖ Experience in implementing SQL Server security and Object permissions like maintaining\n",
      "Database authentication modes, creation of users, configuring permissions and assigning roles\n",
      "to users.\n",
      "\n",
      "DBA Support Analyst\n",
      "\n",
      "Microsoft Corporation -  Redmond, WA -\n",
      "\n",
      "https://www.indeed.com/r/Alok-Khandai/5be849e443b8f467?isid=rex-download&ikw=download-top&co=IN\n",
      "\n",
      "\n",
      "July 2016 to Present\n",
      "\n",
      "Client Description:\n",
      "Microsoft Corporation is an American public multinational corporation headquartered in\n",
      "Redmond, Washington, USA that develops, manufactures, licenses, and supports a wide range of\n",
      "products and services predominantly related to computing through its various product divisions.\n",
      "\n",
      "Environment:\n",
      "Microsoft has E2E development and production environment of more than 25000 servers and\n",
      "applications. We are responsible for pro-active monitoring of all the servers and their jobs using\n",
      "monitoring tools to reduce critical business impact by alerting respective peer teams. Microsoft\n",
      "Service Enterprise an ITSM tools are used for ticketing and SharePoint portal is used to store all\n",
      "technical and process documentation.\n",
      "\n",
      "Roles and Responsibilities:\n",
      "• Responsible for Database support, troubleshooting, planning and migration. Resource planning\n",
      "and coordination for application migrations with project managers, application and web app\n",
      "teams. Project involved guidance and adherence to standardized procedures for planned data\n",
      "center consolidation for worldwide centers using in-house corporate and third party applications\n",
      "based on SQL 2000 in upgrade project to SQL 2005.\n",
      "• Monitoring of database size and disk space in Production, Staging & Development environments\n",
      "• Performed installation of SQL Enterprise 2005 64bit version on Windows 2003 servers on\n",
      "Enterprise systems of clustered and standalone servers in enterprise Data Centers. Patch\n",
      "applications.\n",
      "• Failover cluster testing and resolution on HP servers as well as monitoring and backup reporting\n",
      "setup with Microsoft Operations Manager and backup teams.\n",
      "• Working in Microsoft production environment which includes applications and servers.\n",
      "• Configured Transactional Replication and Log Shipping with SQL Server Management Studio as\n",
      "well as basic account management and troubleshooting with connectivity, security and firewall\n",
      "issues.\n",
      "• Handling issues related to Server Availability, Performance.\n",
      "• Performed Production support and on Call duties\n",
      "• Conducted Performance Tuning using SQL Profiler and Windows Performance Monitor.\n",
      "• Worked with various business groups while developing their applications, assisting in database\n",
      "design, installing SQL Server clients, phasing from development to QA and to Production\n",
      "environment.\n",
      "\n",
      "Previous Project\n",
      "❖ Project Title: Finance Support\n",
      "❖ Client: Costco Wholesale Corporation (USA)\n",
      "❖ Team size: 22\n",
      "❖ Role: DBA Support Analyst\n",
      "❖ Environment: Window 10\n",
      "\n",
      "(SQL DBA Analyst) Engineer\n",
      "\n",
      "HCL Technologies -  Bengaluru, Karnataka -\n",
      "\n",
      "November 2014 to July 2016\n",
      "\n",
      "〓 Performed server installation and configurations for SQL Server 2005 and SQL Server 2000.\n",
      "\n",
      "\n",
      "\n",
      "〓 Performed installation of SQL Server Service Packs\n",
      "〓 Upgraded databases from SQL Server 2000 to SQL Server 2005.\n",
      "〓 Scheduled Full and Transactional log backups for the user created and system databases in\n",
      "the production environment using the Database Maintenance Plan Wizard.\n",
      "〓 Setup backup and restoration jobs for development and QA environments\n",
      "〓 Created transactional replication for the reporting applications.\n",
      "〓 Implemented disaster recovery solution at the remote site for the production databases using\n",
      "Log Shipping.\n",
      "〓 Used System monitor to find the bottlenecks in CPU, Disk I/O and memory devices and\n",
      "improved the database server performance.\n",
      "〓 Used SQL Server Profiler to monitor and record database activities of particular users and\n",
      "applications.\n",
      "〓 Used DBCC commands to troubleshoot issues related to database consistency\n",
      "〓 Worked with various business groups while developing their applications, assisting in database\n",
      "design, installing SQL Server clients, phasing from development to QA and to Production\n",
      "environment\n",
      "\n",
      "Microsoft Corporation -\n",
      "\n",
      "November 2014 to July 2016\n",
      "\n",
      "Client Description:\n",
      "\n",
      "❖ Costco Wholesale Corporation operates an international chain of membership warehouses,\n",
      "mainly under the \"Costco Wholesale\" name, that carry quality, brand name merchandise at\n",
      "substantially lower prices than are typically found at conventional wholesale or retail sources. The\n",
      "warehouses are designed to help small-to-medium-sized businesses reduce costs in purchasing\n",
      "for resale and for everyday business use. Individuals may also purchase for their personal needs.\n",
      "\n",
      "❖ Responsibilities:\n",
      "\n",
      "➢ Performed server installation and configurations for SQL Server 2005 and SQL Server 2000.\n",
      "➢ Performed installation of SQL Server Service Packs\n",
      "➢ Upgraded databases from SQL Server 2000 to SQL Server 2005.\n",
      "➢ Scheduled Full and Transactional log backups for the user created and system databases in\n",
      "the production environment using the Database Maintenance Plan Wizard.\n",
      "➢ Setup backup and restoration jobs for development and QA environments\n",
      "➢ Created transactional replication for the reporting applications.\n",
      "➢ Implemented disaster recovery solution at the remote site for the production databases using\n",
      "Log Shipping.\n",
      "➢ Used System monitor to find the bottlenecks in CPU, Disk I/O and memory devices and improved\n",
      "the database server performance.\n",
      "➢ Used SQL Server Profiler to monitor and record database activities of particular users and\n",
      "applications.\n",
      "➢ Used DBCC commands to troubleshoot issues related to database consistency\n",
      "➢ Worked with various business groups while developing their applications, assisting in database\n",
      "design, installing SQL Server clients, phasing from development to QA and to Production\n",
      "environment\n",
      "\n",
      "\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "B.Tech in Computer Science and Engineering in CSE\n",
      "\n",
      "Indira Gandhi Institute Of Technology\n",
      "\n",
      "2012\n",
      "\n",
      "SKILLS\n",
      "\n",
      "Database (3 years), SQL (3 years), Sql Dba\n",
      "\n",
      "ADDITIONAL INFORMATION\n",
      "\n",
      "TECHNICAL PROFICIENCY\n",
      "❖ Operating Environment: […] Windows95/98/XP/NT\n",
      "❖ Database Tool: SQL Management Studio (MSSQL), Business\n",
      "Development Studio, Visual studio 2005\n",
      "❖ Database Language: SQL, PL/SQL\n",
      "❖ Ticket Tracking Tool: Service Now\n",
      "❖ Reporting Tools: MS Reporting Services, SAS\n",
      "❖ Languages: C, C++, PL/SQL\n",
      "resume entity list:[{'label': ['Skills'], 'points': [{'start': 8098, 'end': 8383, 'text': '❖ Operating Environment: […] Windows95/98/XP/NT\\n❖ Database Tool: SQL Management Studio (MSSQL), Business\\nDevelopment Studio, Visual studio 2005\\n❖ Database Language: SQL, PL/SQL\\n❖ Ticket Tracking Tool: Service Now\\n❖ Reporting Tools: MS Reporting Services, SAS\\n❖ Languages: C, C++, PL/SQL'}]}, {'label': ['Skills'], 'points': [{'start': 8008, 'end': 8049, 'text': 'Database (3 years), SQL (3 years), Sql Dba'}]}, {'label': ['Graduation Year'], 'points': [{'start': 7994, 'end': 7997, 'text': '2012'}]}, {'label': ['College Name'], 'points': [{'start': 7955, 'end': 7991, 'text': 'Indira Gandhi Institute Of Technology'}]}, {'label': ['College Name'], 'points': [{'start': 7904, 'end': 7952, 'text': 'B.Tech in Computer Science and Engineering in CSE'}]}, {'label': ['Companies worked at'], 'points': [{'start': 6199, 'end': 6219, 'text': 'Microsoft Corporation'}]}, {'label': ['Location'], 'points': [{'start': 5016, 'end': 5024, 'text': 'Bengaluru'}]}, {'label': ['Companies worked at'], 'points': [{'start': 4996, 'end': 5011, 'text': 'HCL Technologies'}]}, {'label': ['Designation'], 'points': [{'start': 4969, 'end': 4983, 'text': 'SQL DBA Analyst'}]}, {'label': ['Designation'], 'points': [{'start': 4922, 'end': 4940, 'text': 'DBA Support Analyst'}]}, {'label': ['projects'], 'points': [{'start': 4836, 'end': 4851, 'text': ' Finance Support'}]}, {'label': ['Companies worked at'], 'points': [{'start': 2519, 'end': 2539, 'text': 'Microsoft Corporation'}]}, {'label': ['Email Address'], 'points': [{'start': 2391, 'end': 2432, 'text': 'indeed.com/r/Alok-Khandai/5be849e443b8f467'}]}, {'label': ['Companies worked at'], 'points': [{'start': 2339, 'end': 2359, 'text': 'Microsoft Corporation'}]}, {'label': ['Designation'], 'points': [{'start': 2318, 'end': 2336, 'text': 'DBA Support Analyst'}]}, {'label': ['Skills'], 'points': [{'start': 1607, 'end': 1658, 'text': 'SQL Database Administration, System Analysis, Design'}]}, {'label': ['Years of Experience'], 'points': [{'start': 1577, 'end': 1585, 'text': '3.5 Years'}]}, {'label': ['Location'], 'points': [{'start': 1522, 'end': 1530, 'text': 'Bengaluru'}]}, {'label': ['Companies worked at'], 'points': [{'start': 1512, 'end': 1517, 'text': 'UNISYS'}]}, {'label': ['Designation'], 'points': [{'start': 1472, 'end': 1509, 'text': 'Operational Analyst (SQL DBA) Engineer'}]}, {'label': ['Location'], 'points': [{'start': 1433, 'end': 1441, 'text': 'Bengaluru'}]}, {'label': ['Skills'], 'points': [{'start': 188, 'end': 239, 'text': 'SQL Database Administration, System Analysis, Design'}]}, {'label': ['Email Address'], 'points': [{'start': 105, 'end': 146, 'text': 'indeed.com/r/Alok-Khandai/5be849e443b8f467'}]}, {'label': ['Location'], 'points': [{'start': 62, 'end': 70, 'text': 'Bengaluru'}]}, {'label': ['Companies worked at'], 'points': [{'start': 54, 'end': 59, 'text': 'UNISYS'}]}, {'label': ['Designation'], 'points': [{'start': 13, 'end': 50, 'text': 'Operational Analyst (SQL DBA) Engineer'}]}, {'label': ['Name'], 'points': [{'start': 0, 'end': 11, 'text': 'Alok Khandai'}]}]\n"
     ]
    }
   ],
   "source": [
    "## TODO print the resume text\n",
    "print(\"\"+str(resume.get(\"content\")))\n",
    "## TODO print the resume's list of entity annotations\n",
    "print(\"resume entity list:\"+str(resume.get(\"annotation\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore the list of entity labels\n",
    "The entity list is a list of dictionaries, we want to explore this list\n",
    "1. Cycle through the entities in the list. You can use a 'for' loop for this\n",
    "2. For each entity - which will be a dictionary - print out each key and each value for the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label-----------------------------['Email Address']\n",
      "points-----------------------------[{'start': 1155, 'end': 1198, 'text': 'indeed.com/r/Afreen-Jamadar/8baf379b705e37c6'}]\n",
      "label-----------------------------['Links']\n",
      "points-----------------------------[{'start': 1143, 'end': 1239, 'text': 'https://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN'}]\n",
      "label-----------------------------['Skills']\n",
      "points-----------------------------[{'start': 743, 'end': 1140, 'text': 'Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.'}]\n",
      "label-----------------------------['Graduation Year']\n",
      "points-----------------------------[{'start': 729, 'end': 732, 'text': '2016'}]\n",
      "label-----------------------------['College Name']\n",
      "points-----------------------------[{'start': 675, 'end': 702, 'text': 'Shivaji University Kolhapur '}]\n",
      "label-----------------------------['Degree']\n",
      "points-----------------------------[{'start': 631, 'end': 672, 'text': 'Bachelor of Engg in Information Technology'}]\n",
      "label-----------------------------['Graduation Year']\n",
      "points-----------------------------[{'start': 625, 'end': 629, 'text': '2017\\n'}]\n",
      "label-----------------------------['College Name']\n",
      "points-----------------------------[{'start': 614, 'end': 622, 'text': 'CDAC ACTS'}]\n",
      "label-----------------------------['Degree']\n",
      "points-----------------------------[{'start': 606, 'end': 611, 'text': 'PG-DAC'}]\n",
      "label-----------------------------['Companies worked at']\n",
      "points-----------------------------[{'start': 438, 'end': 453, 'text': 'Cisco Networking'}]\n",
      "label-----------------------------['Email Address']\n",
      "points-----------------------------[{'start': 104, 'end': 147, 'text': 'indeed.com/r/Afreen-Jamadar/8baf379b705e37c6'}]\n",
      "label-----------------------------['Location']\n",
      "points-----------------------------[{'start': 62, 'end': 67, 'text': 'Sangli'}]\n",
      "label-----------------------------['Name']\n",
      "points-----------------------------[{'start': 0, 'end': 13, 'text': 'Afreen Jamadar'}]\n"
     ]
    }
   ],
   "source": [
    "## explore entity list\n",
    "entity = resume.get(\"annotation\")\n",
    "\n",
    "##TODO print out each key and each value for each entity in the entities list\n",
    "for e in entity:\n",
    "    for key,val in e.items():\n",
    "        print (str(key)+\"-----------------------------\"+str(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question: What keys do the entity entries have? What is the datatype of the values of these keys?\n",
    "label & points --> Datatypes: keys always string and values always lists\n",
    "##### Question: What do these keys and values mean? (think of their significance as entity labels)\n",
    "labels are headlines & points are where to put the text and the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert  data to \"spacy\" offset format\n",
    "Before we go any further, we need to convert the data into a slightly more compact format. This format is the format we will be using to train our first models in the next part of the challenge. Here we will do the following:\n",
    "1. Use the provided data conversion function\n",
    "2. Convert the data with that function, storing the results in a variable\n",
    "3. Inspect the converted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701\n",
      "('Afreen Jamadar\\n'\n",
      " 'Active member of IIIT Committee in Third year\\n'\n",
      " '\\n'\n",
      " 'Sangli, Maharashtra - Email me on Indeed: '\n",
      " 'indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\\n'\n",
      " '\\n'\n",
      " 'I wish to use my knowledge, skills and conceptual understanding to create '\n",
      " 'excellent team\\n'\n",
      " 'environments and work consistently achieving organization objectives '\n",
      " 'believes in taking initiative\\n'\n",
      " 'and work to excellence in my work.\\n'\n",
      " '\\n'\n",
      " 'WORK EXPERIENCE\\n'\n",
      " '\\n'\n",
      " 'Active member of IIIT Committee in Third year\\n'\n",
      " '\\n'\n",
      " 'Cisco Networking -  Kanpur, Uttar Pradesh\\n'\n",
      " '\\n'\n",
      " 'organized by Techkriti IIT Kanpur and Azure Skynet.\\n'\n",
      " 'PERSONALLITY TRAITS:\\n'\n",
      " '• Quick learning ability\\n'\n",
      " '• hard working\\n'\n",
      " '\\n'\n",
      " 'EDUCATION\\n'\n",
      " '\\n'\n",
      " 'PG-DAC\\n'\n",
      " '\\n'\n",
      " 'CDAC ACTS\\n'\n",
      " '\\n'\n",
      " '2017\\n'\n",
      " '\\n'\n",
      " 'Bachelor of Engg in Information Technology\\n'\n",
      " '\\n'\n",
      " 'Shivaji University Kolhapur -  Kolhapur, Maharashtra\\n'\n",
      " '\\n'\n",
      " '2016\\n'\n",
      " '\\n'\n",
      " 'SKILLS\\n'\n",
      " '\\n'\n",
      " 'Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 '\n",
      " 'year), MICROSOFT\\n'\n",
      " 'ACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n'\n",
      " '\\n'\n",
      " 'ADDITIONAL INFORMATION\\n'\n",
      " '\\n'\n",
      " 'TECHNICAL SKILLS:\\n'\n",
      " '\\n'\n",
      " '• Programming Languages: C, C++, Java, .net, php.\\n'\n",
      " '• Web Designing: HTML, XML\\n'\n",
      " '• Operating Systems: Windows […] Windows Server 2003, Linux.\\n'\n",
      " '• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\\n'\n",
      " '\\n'\n",
      " 'https://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN',\n",
      " {'entities': [(1155, 1199, 'Email Address'),\n",
      "               (1143, 1240, 'Links'),\n",
      "               (743, 1141, 'Skills'),\n",
      "               (729, 733, 'Graduation Year'),\n",
      "               (675, 703, 'College Name'),\n",
      "               (631, 673, 'Degree'),\n",
      "               (625, 630, 'Graduation Year'),\n",
      "               (614, 623, 'College Name'),\n",
      "               (606, 612, 'Degree'),\n",
      "               (438, 454, 'Companies worked at'),\n",
      "               (104, 148, 'Email Address'),\n",
      "               (62, 68, 'Location'),\n",
      "               (0, 14, 'Name')]})\n"
     ]
    }
   ],
   "source": [
    "## data conversion method\n",
    "def convert_data(data):\n",
    "    \"\"\"\n",
    "    Creates NER training data in Spacy format from JSON dataset\n",
    "    Outputs the Spacy training data which can be used for Spacy training.\n",
    "    \"\"\"\n",
    "    text = data['content']\n",
    "    entities = []\n",
    "    if data['annotation'] is not None:\n",
    "        for annotation in data['annotation']:\n",
    "            # only a single point in text annotation.\n",
    "            point = annotation['points'][0]\n",
    "            labels = annotation['label']\n",
    "            # handle both list of labels or a single label.\n",
    "            if not isinstance(labels, list):\n",
    "                labels = [labels]\n",
    "            for label in labels:\n",
    "                # dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n",
    "                entities.append((point['start'], point['end'] + 1, label))\n",
    "    return (text, {\"entities\": entities})\n",
    "   \n",
    "## TODO using a loop or list comprehension, convert each resume in all_resumes using the convert function above, storing the result\n",
    "converted_resumes = [convert_data(resume) for resume in all_resumes]\n",
    "## TODO print the number of resumes in converted resumes \n",
    "print(len(converted_resumes))\n",
    "from pprint import pprint\n",
    "pprint (converted_resumes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question: how is the converted data different than the original data? How is it the same? \n",
    "Same overall structure of resumes, resume content stored differently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### filter out resumes without annotations\n",
    "A few of the resumes have an empty entity list. We want to filter these resumes out of our data before continuing. We will do the following:\n",
    "1. cycle through all resumes using for loop or list comprehension\n",
    "2. for each resume, if the resume has no labled entities, ignore it. Otherwise save it to new resume list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690\n"
     ]
    }
   ],
   "source": [
    "## TODO filter out resumes where resume entities list is None (you can do this in a one-line list comprehension)\n",
    "## sove to converted_resumes variable\n",
    "converted_resumes = [resume for resume in converted_resumes if len(resume[1]['entities'])>0 ]\n",
    "## TODO print length of new filtered converted_resumes.  \n",
    "print(len(converted_resumes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print all entities for one converted resume\n",
    "The converted data also has an entity list. You should be able to examine this using similar techniques we have used above on the converted data. In the next code block you will write code that will print all of the entities for one resume. TIP each entity entry in the 'entities' list consists of a start index of the entity in the resume text, an end index, and the entity label. We will do the following:\n",
    "1. Store one converted resume in the 'converted_resume' variable\n",
    "2. Find the entity list in the converted_resume\n",
    "3. Cycle through the entities, and - using the start and end index - print the label of the entity and the value of the entity. This will be the text substring pointed to by the start and end index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afreen Jamadar\n",
      "Active member of IIIT Committee in Third year\n",
      "\n",
      "Sangli, Maharashtra - Email me on Indeed: indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\n",
      "\n",
      "I wish to use my knowledge, skills and conceptual understanding to create excellent team\n",
      "environments and work consistently achieving organization objectives believes in taking initiative\n",
      "and work to excellence in my work.\n",
      "\n",
      "WORK EXPERIENCE\n",
      "\n",
      "Active member of IIIT Committee in Third year\n",
      "\n",
      "Cisco Networking -  Kanpur, Uttar Pradesh\n",
      "\n",
      "organized by Techkriti IIT Kanpur and Azure Skynet.\n",
      "PERSONALLITY TRAITS:\n",
      "• Quick learning ability\n",
      "• hard working\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "PG-DAC\n",
      "\n",
      "CDAC ACTS\n",
      "\n",
      "2017\n",
      "\n",
      "Bachelor of Engg in Information Technology\n",
      "\n",
      "Shivaji University Kolhapur -  Kolhapur, Maharashtra\n",
      "\n",
      "2016\n",
      "\n",
      "SKILLS\n",
      "\n",
      "Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\n",
      "ACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\n",
      "\n",
      "ADDITIONAL INFORMATION\n",
      "\n",
      "TECHNICAL SKILLS:\n",
      "\n",
      "• Programming Languages: C, C++, Java, .net, php.\n",
      "• Web Designing: HTML, XML\n",
      "• Operating Systems: Windows […] Windows Server 2003, Linux.\n",
      "• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\n",
      "\n",
      "https://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\n"
     ]
    }
   ],
   "source": [
    "## store one resume in the variable\n",
    "converted_resume = converted_resumes [0]\n",
    "## find text content and store in variable\n",
    "text = converted_resume [0]\n",
    "## find the entities list and store in variable\n",
    "entities_list = None\n",
    "## TODO for each entity, print the label, and the text (text content substring pointed to by start and end index)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question: What are some of the entity labels you see? Are there any entity values that seem surprising or particularly interesting? \n",
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collect unique labels of all entities in dataset\n",
    "Now we are interested in finding out all of the (unique) entity labels which exist in our dataset. Complete and execute the code below to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity labels:  ['links', 'Email Address', 'College Name', 'Relocate to', 'Certifications', 'projects', 'Companies worked at', 'Degree', 'Location', 'Rewards and Achievements', 'des', 'training', 'Links', 'UNKNOWN', 'Can Relocate to', 'College', 'abc', 'Years of Experience', 'Skills', 'Address', 'University', 'Designation', 'state', 'Graduation Year', 'Name']\n"
     ]
    }
   ],
   "source": [
    "## collect names of all entities in complete resume dataset\n",
    "all_labels = list()\n",
    "for res in converted_resumes:\n",
    "    ## entity list of res\n",
    "    entity_list = [label[2] for label in res[1] ['entities']] \n",
    "\n",
    "    ## TODO extend all_labels with labels of entities \n",
    "    all_labels.extend(entity_list)\n",
    "    ##all_labels.           \n",
    "## TODO all_labels is not yet unique. Make the list a set of unique values\n",
    "unique_labels = list(set(all_labels))\n",
    "## Print unique entity labels\n",
    "print(\"Entity labels: \",unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see all entity labels in our dataset. Do some of them seem particularly interesting to you? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose up to 3 Entities from the list that you would like to use for training a named entity recognition model. \n",
    "##### Question: which entities did you choose? \n",
    "Certification, Skills, University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate entities\n",
    "Now we need to check that there is adequate training data for the entities you have chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies worked at\n",
      "Docs with Companies worked at: 627\n",
      "Total count of Companies worked at: 2830\n",
      "Degree\n",
      "Docs with Degree: 606\n",
      "Total count of Degree: 1012\n",
      "University\n",
      "Docs with University: 16\n",
      "Total count of University: 18\n",
      "Designation\n",
      "Docs with Designation: 650\n",
      "Total count of Designation: 2842\n",
      "Can Relocate to\n",
      "Docs with Can Relocate to: 65\n",
      "Total count of Can Relocate to: 128\n",
      "Relocate to\n",
      "Docs with Relocate to: 5\n",
      "Total count of Relocate to: 10\n",
      "Years of Experience\n",
      "Docs with Years of Experience: 217\n",
      "Total count of Years of Experience: 623\n",
      "Location\n",
      "Docs with Location: 641\n",
      "Total count of Location: 1976\n",
      "Rewards and Achievements\n",
      "Docs with Rewards and Achievements: 13\n",
      "Total count of Rewards and Achievements: 25\n",
      "state\n",
      "Docs with state: 5\n",
      "Total count of state: 11\n",
      "College Name\n",
      "Docs with College Name: 497\n",
      "Total count of College Name: 1160\n",
      "training\n",
      "Docs with training: 1\n",
      "Total count of training: 1\n",
      "Graduation Year\n",
      "Docs with Graduation Year: 255\n",
      "Total count of Graduation Year: 566\n",
      "abc\n",
      "Docs with abc: 1\n",
      "Total count of abc: 1\n",
      "projects\n",
      "Docs with projects: 9\n",
      "Total count of projects: 10\n",
      "Certifications\n",
      "Docs with Certifications: 7\n",
      "Total count of Certifications: 7\n",
      "College\n",
      "Docs with College: 88\n",
      "Total count of College: 148\n",
      "Skills\n",
      "Docs with Skills: 536\n",
      "Total count of Skills: 2152\n"
     ]
    }
   ],
   "source": [
    "## TODO store entity label names for the entities you want to work with in an array \n",
    "chosen_entity_label = ['Companies worked at', 'Degree', 'University', 'Designation', 'Can Relocate to', 'Relocate to', 'Years of Experience', 'Location', 'Rewards and Achievements', 'state', 'College Name', 'training', 'Graduation Year', 'projects', 'Certifications', 'College', 'Skills']\n",
    "## for each chosen entity label, count how many documents have a labeled entity for that label, and how many labeled entities total there are \n",
    "\n",
    "## for that entity\n",
    "for chosen in chosen_entity_label:\n",
    "    found_docs_with_entity = 0\n",
    "    entity_count = 0\n",
    "    for resume in converted_resumes:\n",
    "        entity_list = resume[1][\"entities\"]\n",
    "        _,_,labels = zip(*entity_list)\n",
    "        if chosen in labels:\n",
    "            found_docs_with_entity+=1\n",
    "            entity_count+=len([l for l in labels if l == chosen])\n",
    "    print(chosen)\n",
    "    print(\"Docs with {}: {}\".format(chosen,found_docs_with_entity))\n",
    "    print(\"Total count of {}: {}\".format(chosen,entity_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Question: Is adequate training data available for the entities you have chosen? (there should be at least several hundered examples total of each entity)\n",
    "Only \"Skills\" has sufficient data, so I switched to Skills, Location, Degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save converted data for later use\n",
    "We are almost done with the first part of the challenge! One more detail. We need to save the \"converted_resumes\" list so we can load it in the next notebook. We will do the following:\n",
    "1. Store the location we want to save the data to in the 'converted_resumes_path' variable\n",
    "2. Using python's 'open' function and the 'json' module's 'dump' function, save the data to disk. Make sure to create missing directories (if applicable) using python's \"os.makedirs\" function. Save the file with a \".json\" file extension\n",
    "3. Check the filesystem if the file exists and is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_resumes_path = \"../dataset/converted_resumes.json\"\n",
    "##TODO save converted resumes to path using \"open\" and json's \"dump\" function. \n",
    "with open(converted_resumes_path, 'w') as outfile:\n",
    "    json.dump(converted_resumes, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    "We are done with part one. Now we will go on to train our own NER Models with the dataset and the entities we have chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
